{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_TvzkL1P6jy4",
        "-EmBEl4M67W3",
        "BrdnUOFU7NST"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install Everything"
      ],
      "metadata": {
        "id": "_TvzkL1P6jy4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0k8dpX3-6Zk4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abee6325-eb6a-4acb-8785-0e1397105350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/68.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m68.2/68.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q requests pandas sqlite-utils python-dotenv numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timezone\n",
        "from typing import Dict, List, Optional, Any, Union\n",
        "from dotenv import load_dotenv\n",
        "import time\n",
        "import logging\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
      ],
      "metadata": {
        "id": "Yi0ibTwE6km7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_environment():\n",
        "    \"\"\"Setup environment variables for Metaculus API\"\"\"\n",
        "\n",
        "    # Create .env file content\n",
        "    env_content = \"\"\"# Metaculus Tracker Configuration\n",
        "# Get your API token from: https://www.metaculus.com/settings/\n",
        "METACULUS_API_TOKEN=9944b09199c62bcf9418ad846dd0e4bbdfc6ee4b\n",
        "\n",
        "# API Endpoints\n",
        "METACULUS_API_URL=https://www.metaculus.com/api\n",
        "METACULUS_API_VERSION=v1\n",
        "\n",
        "# Database Configuration\n",
        "DB_PATH=/content/metaculus_tracker.db\n",
        "\n",
        "# Tracking Configuration\n",
        "REQUESTS_PER_HOUR=1000\n",
        "MIN_FORECASTERS=10\n",
        "FETCH_COMMENTS=true\n",
        "FETCH_FORECASTS=true\n",
        "\"\"\"\n",
        "\n",
        "    # Write .env file\n",
        "    env_path = Path(\"/content/.env\")\n",
        "    env_path.write_text(env_content)\n",
        "\n",
        "    print(f\"‚úÖ Environment configuration created!\")\n",
        "    print(f\"üìÅ Environment file created at: {env_path}\")\n",
        "    print(\"\\n‚ö†Ô∏è IMPORTANT: Edit /content/.env and add your Metaculus API token\")\n",
        "    print(\"   Get your token from: https://www.metaculus.com/settings/\")\n",
        "    print(\"   Look for 'API Access' section\")\n",
        "\n",
        "    # Load environment variables\n",
        "    load_dotenv(env_path)\n",
        "\n",
        "    return {\n",
        "        \"api_url\": os.getenv(\"METACULUS_API_URL\", \"https://www.metaculus.com/api\"),\n",
        "        \"api_token\": os.getenv(\"METACULUS_API_TOKEN\"),\n",
        "        \"db_path\": os.getenv(\"DB_PATH\", \"/content/metaculus_tracker.db\")\n",
        "    }\n",
        "\n",
        "# Execute environment setup\n",
        "env_config = setup_environment()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YB9shLIc6kpT",
        "outputId": "2248d128-f5c7-4720-ccc5-66849d100301"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Environment configuration created!\n",
            "üìÅ Environment file created at: /content/.env\n",
            "\n",
            "‚ö†Ô∏è IMPORTANT: Edit /content/.env and add your Metaculus API token\n",
            "   Get your token from: https://www.metaculus.com/settings/\n",
            "   Look for 'API Access' section\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_database():\n",
        "    \"\"\"Create SQLite database with all required tables\"\"\"\n",
        "\n",
        "    db_path = os.getenv(\"DB_PATH\", \"/content/metaculus_tracker.db\")\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Create Posts table (equivalent to Events)\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS posts (\n",
        "        id INTEGER PRIMARY KEY,\n",
        "        title TEXT,\n",
        "        short_title TEXT,\n",
        "        slug TEXT UNIQUE,\n",
        "        author_id INTEGER,\n",
        "        author_username TEXT,\n",
        "        status TEXT,\n",
        "        resolved BOOLEAN,\n",
        "        published_at TEXT,\n",
        "        actual_close_time TEXT,\n",
        "        scheduled_close_time TEXT,\n",
        "        scheduled_resolve_time TEXT,\n",
        "        open_time TEXT,\n",
        "        nr_forecasters INTEGER,\n",
        "        comment_count INTEGER,\n",
        "        vote_score INTEGER,\n",
        "        forecasts_count INTEGER,\n",
        "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
        "        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    # Create Questions table (equivalent to Markets)\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS questions (\n",
        "        id INTEGER PRIMARY KEY,\n",
        "        post_id INTEGER,\n",
        "        title TEXT,\n",
        "        type TEXT,  -- binary, numeric, multiple_choice, date\n",
        "        status TEXT,\n",
        "        resolution TEXT,\n",
        "        resolution_criteria TEXT,\n",
        "        fine_print TEXT,\n",
        "        open_time TEXT,\n",
        "        scheduled_close_time TEXT,\n",
        "        actual_close_time TEXT,\n",
        "        scheduled_resolve_time TEXT,\n",
        "        actual_resolve_time TEXT,\n",
        "        options TEXT,  -- JSON for multiple choice options\n",
        "        scaling TEXT,  -- JSON for numeric scaling parameters\n",
        "        aggregation_data TEXT,  -- JSON for latest aggregation\n",
        "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
        "        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
        "        FOREIGN KEY (post_id) REFERENCES posts(id)\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    # Create Conditional Questions table\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS conditional_questions (\n",
        "        id INTEGER PRIMARY KEY,\n",
        "        parent_post_id INTEGER,\n",
        "        condition_id INTEGER,\n",
        "        condition_child_id INTEGER,\n",
        "        question_yes_id INTEGER,\n",
        "        question_no_id INTEGER,\n",
        "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
        "        FOREIGN KEY (parent_post_id) REFERENCES posts(id),\n",
        "        FOREIGN KEY (condition_id) REFERENCES questions(id),\n",
        "        FOREIGN KEY (condition_child_id) REFERENCES questions(id)\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    # Create Group Questions table\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS group_questions (\n",
        "        id INTEGER PRIMARY KEY,\n",
        "        parent_post_id INTEGER,\n",
        "        group_variable TEXT,\n",
        "        graph_type TEXT,\n",
        "        description TEXT,\n",
        "        resolution_criteria TEXT,\n",
        "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
        "        FOREIGN KEY (parent_post_id) REFERENCES posts(id)\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    # Create Forecasts table\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS forecasts (\n",
        "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        question_id INTEGER,\n",
        "        forecaster_id INTEGER,\n",
        "        forecaster_username TEXT,\n",
        "        start_time TEXT,\n",
        "        end_time TEXT,\n",
        "        forecaster_count INTEGER,\n",
        "        probability_yes REAL,  -- For binary questions\n",
        "        forecast_values TEXT,  -- JSON for continuous/multiple choice\n",
        "        continuous_cdf TEXT,  -- JSON for continuous CDF\n",
        "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
        "        FOREIGN KEY (question_id) REFERENCES questions(id)\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    # Create Comments table\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS comments (\n",
        "        id INTEGER PRIMARY KEY,\n",
        "        post_id INTEGER,\n",
        "        author_id INTEGER,\n",
        "        author_username TEXT,\n",
        "        parent_id INTEGER,\n",
        "        root_id INTEGER,\n",
        "        text TEXT,\n",
        "        vote_score INTEGER,\n",
        "        included_forecast BOOLEAN,\n",
        "        created_at TEXT,\n",
        "        fetched_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
        "        FOREIGN KEY (post_id) REFERENCES posts(id)\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    # Create Projects/Categories table\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS projects (\n",
        "        id INTEGER PRIMARY KEY,\n",
        "        name TEXT,\n",
        "        slug TEXT,\n",
        "        type TEXT,\n",
        "        description TEXT,\n",
        "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    # Create Post_Projects junction table\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS post_projects (\n",
        "        post_id INTEGER,\n",
        "        project_id INTEGER,\n",
        "        PRIMARY KEY (post_id, project_id),\n",
        "        FOREIGN KEY (post_id) REFERENCES posts(id),\n",
        "        FOREIGN KEY (project_id) REFERENCES projects(id)\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    # Create Aggregations table for tracking prediction aggregates\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS aggregations (\n",
        "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        question_id INTEGER,\n",
        "        aggregation_type TEXT,  -- metaculus_prediction, recency_weighted, unweighted\n",
        "        start_time TEXT,\n",
        "        end_time TEXT,\n",
        "        forecaster_count INTEGER,\n",
        "        centers TEXT,  -- JSON array\n",
        "        interval_lower_bounds TEXT,  -- JSON array\n",
        "        interval_upper_bounds TEXT,  -- JSON array\n",
        "        forecast_values TEXT,  -- JSON for continuous\n",
        "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
        "        FOREIGN KEY (question_id) REFERENCES questions(id)\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    print(f\"‚úÖ Database setup complete at: {db_path}\")\n",
        "    print(\"üìä Tables created:\")\n",
        "    print(\"   - posts (main questions/events)\")\n",
        "    print(\"   - questions (individual forecasting questions)\")\n",
        "    print(\"   - conditional_questions, group_questions\")\n",
        "    print(\"   - forecasts, comments, projects\")\n",
        "    print(\"   - aggregations (community predictions)\")\n",
        "\n",
        "# Execute database setup\n",
        "setup_database()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTfg_eeG6krw",
        "outputId": "dd302cf3-9081-48ef-b68f-a46efc2a81c8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Database setup complete at: /content/metaculus_tracker.db\n",
            "üìä Tables created:\n",
            "   - posts (main questions/events)\n",
            "   - questions (individual forecasting questions)\n",
            "   - conditional_questions, group_questions\n",
            "   - forecasts, comments, projects\n",
            "   - aggregations (community predictions)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fetch and Store Active Questions/Posts"
      ],
      "metadata": {
        "id": "-EmBEl4M67W3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_all_posts(status_filter=\"open\", limit_per_page=100):\n",
        "    \"\"\"Fetch all posts/questions from Metaculus API\"\"\"\n",
        "\n",
        "    api_url = os.getenv(\"METACULUS_API_URL\", \"https://www.metaculus.com/api\")\n",
        "    api_token = os.getenv(\"METACULUS_API_TOKEN\")\n",
        "    db_path = os.getenv(\"DB_PATH\")\n",
        "\n",
        "    headers = {}\n",
        "    if api_token and api_token != \"YOUR_TOKEN_HERE\":\n",
        "        headers[\"Authorization\"] = f\"Token {api_token}\"\n",
        "\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    all_posts = []\n",
        "    next_url = f\"{api_url}/posts/\"\n",
        "    params = {\n",
        "        \"limit\": limit_per_page,\n",
        "        \"status\": status_filter,\n",
        "        \"has_predictions\": \"true\",\n",
        "        \"order_by\": \"-forecasters_count\"\n",
        "    }\n",
        "\n",
        "    print(f\"üîç Fetching {status_filter} questions from Metaculus...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    page = 0\n",
        "    while next_url:\n",
        "        try:\n",
        "            page += 1\n",
        "            response = requests.get(next_url, headers=headers, params=params if page == 1 else None)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            data = response.json()\n",
        "            results = data.get(\"results\", [])\n",
        "\n",
        "            if not results:\n",
        "                break\n",
        "\n",
        "            for post in results:\n",
        "                # Store post in database\n",
        "                cursor.execute(\"\"\"\n",
        "                INSERT OR REPLACE INTO posts\n",
        "                (id, title, short_title, slug, author_id, author_username,\n",
        "                 status, resolved, published_at, actual_close_time,\n",
        "                 scheduled_close_time, scheduled_resolve_time, open_time,\n",
        "                 nr_forecasters, comment_count, vote_score, forecasts_count)\n",
        "                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "                \"\"\", (\n",
        "                    post.get('id'),\n",
        "                    post.get('title'),\n",
        "                    post.get('short_title'),\n",
        "                    post.get('slug'),\n",
        "                    post.get('author_id'),\n",
        "                    post.get('author_username'),\n",
        "                    post.get('status'),\n",
        "                    post.get('resolved'),\n",
        "                    post.get('published_at'),\n",
        "                    post.get('actual_close_time'),\n",
        "                    post.get('scheduled_close_time'),\n",
        "                    post.get('scheduled_resolve_time'),\n",
        "                    post.get('open_time'),\n",
        "                    post.get('nr_forecasters'),\n",
        "                    post.get('comment_count'),\n",
        "                    post.get('vote', {}).get('score'),\n",
        "                    post.get('forecasts_count')\n",
        "                ))\n",
        "\n",
        "                # Handle different question types\n",
        "                if 'question' in post:\n",
        "                    store_question(cursor, post['question'], post['id'])\n",
        "\n",
        "                if 'conditional' in post:\n",
        "                    store_conditional_question(cursor, post['conditional'], post['id'])\n",
        "\n",
        "                if 'group_of_questions' in post:\n",
        "                    store_group_questions(cursor, post['group_of_questions'], post['id'])\n",
        "\n",
        "                all_posts.append(post)\n",
        "\n",
        "            print(f\"  üì¶ Page {page}: Fetched {len(results)} posts (Total: {len(all_posts)})\")\n",
        "\n",
        "            # Get next page URL\n",
        "            next_url = data.get(\"next\")\n",
        "\n",
        "            # Rate limiting\n",
        "            time.sleep(0.1)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error fetching posts: {e}\")\n",
        "            break\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(f\"‚úÖ Total posts fetched and stored: {len(all_posts)}\")\n",
        "    return all_posts\n",
        "\n",
        "def store_question(cursor, question, post_id):\n",
        "    \"\"\"Store individual question data\"\"\"\n",
        "    cursor.execute(\"\"\"\n",
        "    INSERT OR REPLACE INTO questions\n",
        "    (id, post_id, title, type, status, resolution, resolution_criteria,\n",
        "     fine_print, open_time, scheduled_close_time, actual_close_time,\n",
        "     scheduled_resolve_time, actual_resolve_time, options, scaling, aggregation_data)\n",
        "    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "    \"\"\", (\n",
        "        question.get('id'),\n",
        "        post_id,\n",
        "        question.get('title'),\n",
        "        question.get('type'),\n",
        "        question.get('status'),\n",
        "        question.get('resolution'),\n",
        "        question.get('resolution_criteria'),\n",
        "        question.get('fine_print'),\n",
        "        question.get('open_time'),\n",
        "        question.get('scheduled_close_time'),\n",
        "        question.get('actual_close_time'),\n",
        "        question.get('scheduled_resolve_time'),\n",
        "        question.get('actual_resolve_time'),\n",
        "        json.dumps(question.get('options')) if question.get('options') else None,\n",
        "        json.dumps(question.get('scaling')) if question.get('scaling') else None,\n",
        "        json.dumps(question.get('aggregations')) if question.get('aggregations') else None\n",
        "    ))\n",
        "\n",
        "def store_conditional_question(cursor, conditional, post_id):\n",
        "    \"\"\"Store conditional question data\"\"\"\n",
        "    cursor.execute(\"\"\"\n",
        "    INSERT OR REPLACE INTO conditional_questions\n",
        "    (id, parent_post_id, condition_id, condition_child_id,\n",
        "     question_yes_id, question_no_id)\n",
        "    VALUES (?, ?, ?, ?, ?, ?)\n",
        "    \"\"\", (\n",
        "        conditional.get('id'),\n",
        "        post_id,\n",
        "        conditional.get('condition', {}).get('id'),\n",
        "        conditional.get('condition_child', {}).get('id'),\n",
        "        conditional.get('question_yes', {}).get('id'),\n",
        "        conditional.get('question_no', {}).get('id')\n",
        "    ))\n",
        "\n",
        "    # Store the individual questions\n",
        "    if 'condition' in conditional:\n",
        "        store_question(cursor, conditional['condition'], post_id)\n",
        "    if 'condition_child' in conditional:\n",
        "        store_question(cursor, conditional['condition_child'], post_id)\n",
        "\n",
        "def store_group_questions(cursor, group, post_id):\n",
        "    \"\"\"Store group of questions data\"\"\"\n",
        "    cursor.execute(\"\"\"\n",
        "    INSERT OR REPLACE INTO group_questions\n",
        "    (id, parent_post_id, group_variable, graph_type,\n",
        "     description, resolution_criteria)\n",
        "    VALUES (?, ?, ?, ?, ?, ?)\n",
        "    \"\"\", (\n",
        "        group.get('id'),\n",
        "        post_id,\n",
        "        group.get('group_variable'),\n",
        "        group.get('graph_type'),\n",
        "        group.get('description'),\n",
        "        group.get('resolution_criteria')\n",
        "    ))\n",
        "\n",
        "    # Store individual questions in the group\n",
        "    for question in group.get('questions', []):\n",
        "        store_question(cursor, question, post_id)\n",
        "\n",
        "# Execute post fetching\n",
        "posts = fetch_all_posts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSja1iAN6kt6",
        "outputId": "99647d53-5e0a-40b6-c4b8-3cfdfc535c9d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Fetching open questions from Metaculus...\n",
            "============================================================\n",
            "  üì¶ Page 1: Fetched 100 posts (Total: 100)\n",
            "  üì¶ Page 2: Fetched 100 posts (Total: 200)\n",
            "  üì¶ Page 3: Fetched 100 posts (Total: 300)\n",
            "  üì¶ Page 4: Fetched 100 posts (Total: 400)\n",
            "  üì¶ Page 5: Fetched 100 posts (Total: 500)\n",
            "  üì¶ Page 6: Fetched 100 posts (Total: 600)\n",
            "  üì¶ Page 7: Fetched 100 posts (Total: 700)\n",
            "  üì¶ Page 8: Fetched 100 posts (Total: 800)\n",
            "  üì¶ Page 9: Fetched 100 posts (Total: 900)\n",
            "  üì¶ Page 10: Fetched 100 posts (Total: 1000)\n",
            "  üì¶ Page 11: Fetched 100 posts (Total: 1100)\n",
            "  üì¶ Page 12: Fetched 100 posts (Total: 1200)\n",
            "  üì¶ Page 13: Fetched 100 posts (Total: 1300)\n",
            "  üì¶ Page 14: Fetched 100 posts (Total: 1400)\n",
            "  üì¶ Page 15: Fetched 100 posts (Total: 1500)\n",
            "  üì¶ Page 16: Fetched 100 posts (Total: 1600)\n",
            "  üì¶ Page 17: Fetched 100 posts (Total: 1700)\n",
            "  üì¶ Page 18: Fetched 100 posts (Total: 1800)\n",
            "  üì¶ Page 19: Fetched 100 posts (Total: 1900)\n",
            "  üì¶ Page 20: Fetched 100 posts (Total: 2000)\n",
            "  üì¶ Page 21: Fetched 100 posts (Total: 2100)\n",
            "  üì¶ Page 22: Fetched 100 posts (Total: 2200)\n",
            "  üì¶ Page 23: Fetched 100 posts (Total: 2300)\n",
            "  üì¶ Page 24: Fetched 100 posts (Total: 2400)\n",
            "  üì¶ Page 25: Fetched 100 posts (Total: 2500)\n",
            "  üì¶ Page 26: Fetched 100 posts (Total: 2600)\n",
            "  üì¶ Page 27: Fetched 100 posts (Total: 2700)\n",
            "  üì¶ Page 28: Fetched 100 posts (Total: 2800)\n",
            "  üì¶ Page 29: Fetched 100 posts (Total: 2900)\n",
            "  üì¶ Page 30: Fetched 100 posts (Total: 3000)\n",
            "  üì¶ Page 31: Fetched 100 posts (Total: 3100)\n",
            "  üì¶ Page 32: Fetched 100 posts (Total: 3200)\n",
            "  üì¶ Page 33: Fetched 100 posts (Total: 3300)\n",
            "  üì¶ Page 34: Fetched 100 posts (Total: 3400)\n",
            "  üì¶ Page 35: Fetched 100 posts (Total: 3500)\n",
            "  üì¶ Page 36: Fetched 100 posts (Total: 3600)\n",
            "  üì¶ Page 37: Fetched 100 posts (Total: 3700)\n",
            "  üì¶ Page 38: Fetched 100 posts (Total: 3800)\n",
            "  üì¶ Page 39: Fetched 100 posts (Total: 3900)\n",
            "  üì¶ Page 40: Fetched 100 posts (Total: 4000)\n",
            "  üì¶ Page 41: Fetched 100 posts (Total: 4100)\n",
            "  üì¶ Page 42: Fetched 100 posts (Total: 4200)\n",
            "  üì¶ Page 43: Fetched 100 posts (Total: 4300)\n",
            "  üì¶ Page 44: Fetched 100 posts (Total: 4400)\n",
            "  üì¶ Page 45: Fetched 100 posts (Total: 4500)\n",
            "  üì¶ Page 46: Fetched 100 posts (Total: 4600)\n",
            "  üì¶ Page 47: Fetched 100 posts (Total: 4700)\n",
            "  üì¶ Page 48: Fetched 100 posts (Total: 4800)\n",
            "  üì¶ Page 49: Fetched 100 posts (Total: 4900)\n",
            "  üì¶ Page 50: Fetched 100 posts (Total: 5000)\n",
            "  üì¶ Page 51: Fetched 100 posts (Total: 5100)\n",
            "  üì¶ Page 52: Fetched 100 posts (Total: 5200)\n",
            "  üì¶ Page 53: Fetched 100 posts (Total: 5300)\n",
            "  üì¶ Page 54: Fetched 100 posts (Total: 5400)\n",
            "  üì¶ Page 55: Fetched 100 posts (Total: 5500)\n",
            "  üì¶ Page 56: Fetched 100 posts (Total: 5600)\n",
            "  üì¶ Page 57: Fetched 100 posts (Total: 5700)\n",
            "  üì¶ Page 58: Fetched 100 posts (Total: 5800)\n",
            "  üì¶ Page 59: Fetched 100 posts (Total: 5900)\n",
            "  üì¶ Page 60: Fetched 100 posts (Total: 6000)\n",
            "  üì¶ Page 61: Fetched 100 posts (Total: 6100)\n",
            "  üì¶ Page 62: Fetched 100 posts (Total: 6200)\n",
            "  üì¶ Page 63: Fetched 100 posts (Total: 6300)\n",
            "  üì¶ Page 64: Fetched 100 posts (Total: 6400)\n",
            "  üì¶ Page 65: Fetched 100 posts (Total: 6500)\n",
            "  üì¶ Page 66: Fetched 100 posts (Total: 6600)\n",
            "  üì¶ Page 67: Fetched 100 posts (Total: 6700)\n",
            "  üì¶ Page 68: Fetched 100 posts (Total: 6800)\n",
            "  üì¶ Page 69: Fetched 100 posts (Total: 6900)\n",
            "  üì¶ Page 70: Fetched 100 posts (Total: 7000)\n",
            "  üì¶ Page 71: Fetched 100 posts (Total: 7100)\n",
            "  üì¶ Page 72: Fetched 100 posts (Total: 7200)\n",
            "  üì¶ Page 73: Fetched 100 posts (Total: 7300)\n",
            "  üì¶ Page 74: Fetched 100 posts (Total: 7400)\n",
            "  üì¶ Page 75: Fetched 100 posts (Total: 7500)\n",
            "  üì¶ Page 76: Fetched 100 posts (Total: 7600)\n",
            "  üì¶ Page 77: Fetched 100 posts (Total: 7700)\n",
            "  üì¶ Page 78: Fetched 100 posts (Total: 7800)\n",
            "  üì¶ Page 79: Fetched 100 posts (Total: 7900)\n",
            "  üì¶ Page 80: Fetched 100 posts (Total: 8000)\n",
            "  üì¶ Page 81: Fetched 100 posts (Total: 8100)\n",
            "  üì¶ Page 82: Fetched 100 posts (Total: 8200)\n",
            "  üì¶ Page 83: Fetched 100 posts (Total: 8300)\n",
            "  üì¶ Page 84: Fetched 100 posts (Total: 8400)\n",
            "  üì¶ Page 85: Fetched 100 posts (Total: 8500)\n",
            "  üì¶ Page 86: Fetched 100 posts (Total: 8600)\n",
            "  üì¶ Page 87: Fetched 100 posts (Total: 8700)\n",
            "  üì¶ Page 88: Fetched 100 posts (Total: 8800)\n",
            "  üì¶ Page 89: Fetched 100 posts (Total: 8900)\n",
            "  üì¶ Page 90: Fetched 100 posts (Total: 9000)\n",
            "  üì¶ Page 91: Fetched 100 posts (Total: 9100)\n",
            "  üì¶ Page 92: Fetched 100 posts (Total: 9200)\n",
            "  üì¶ Page 93: Fetched 100 posts (Total: 9300)\n",
            "  üì¶ Page 94: Fetched 100 posts (Total: 9400)\n",
            "  üì¶ Page 95: Fetched 100 posts (Total: 9500)\n",
            "  üì¶ Page 96: Fetched 100 posts (Total: 9600)\n",
            "  üì¶ Page 97: Fetched 100 posts (Total: 9700)\n",
            "  üì¶ Page 98: Fetched 100 posts (Total: 9800)\n",
            "  üì¶ Page 99: Fetched 100 posts (Total: 9900)\n",
            "  üì¶ Page 100: Fetched 100 posts (Total: 10000)\n",
            "  üì¶ Page 101: Fetched 100 posts (Total: 10100)\n",
            "  üì¶ Page 102: Fetched 100 posts (Total: 10200)\n",
            "  üì¶ Page 103: Fetched 100 posts (Total: 10300)\n",
            "  üì¶ Page 104: Fetched 100 posts (Total: 10400)\n",
            "  üì¶ Page 105: Fetched 100 posts (Total: 10500)\n",
            "  üì¶ Page 106: Fetched 100 posts (Total: 10600)\n",
            "  üì¶ Page 107: Fetched 100 posts (Total: 10700)\n",
            "  üì¶ Page 108: Fetched 100 posts (Total: 10800)\n",
            "  üì¶ Page 109: Fetched 100 posts (Total: 10900)\n",
            "  üì¶ Page 110: Fetched 100 posts (Total: 11000)\n",
            "  üì¶ Page 111: Fetched 100 posts (Total: 11100)\n",
            "  üì¶ Page 112: Fetched 100 posts (Total: 11200)\n",
            "  üì¶ Page 113: Fetched 100 posts (Total: 11300)\n",
            "  üì¶ Page 114: Fetched 100 posts (Total: 11400)\n",
            "  üì¶ Page 115: Fetched 100 posts (Total: 11500)\n",
            "  üì¶ Page 116: Fetched 100 posts (Total: 11600)\n",
            "  üì¶ Page 117: Fetched 100 posts (Total: 11700)\n",
            "  üì¶ Page 118: Fetched 100 posts (Total: 11800)\n",
            "  üì¶ Page 119: Fetched 100 posts (Total: 11900)\n",
            "  üì¶ Page 120: Fetched 100 posts (Total: 12000)\n",
            "  üì¶ Page 121: Fetched 100 posts (Total: 12100)\n",
            "  üì¶ Page 122: Fetched 56 posts (Total: 12156)\n",
            "============================================================\n",
            "‚úÖ Total posts fetched and stored: 12156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_question_details(question_ids=None, sample_size=10):\n",
        "    \"\"\"Fetch detailed data for specific questions including aggregations\"\"\"\n",
        "\n",
        "    api_url = os.getenv(\"METACULUS_API_URL\", \"https://www.metaculus.com/api\")\n",
        "    api_token = os.getenv(\"METACULUS_API_TOKEN\")\n",
        "    db_path = os.getenv(\"DB_PATH\")\n",
        "\n",
        "    headers = {}\n",
        "    if api_token and api_token != \"YOUR_TOKEN_HERE\":\n",
        "        headers[\"Authorization\"] = f\"Token {api_token}\"\n",
        "\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # If no specific IDs provided, get sample of active questions\n",
        "    if question_ids is None:\n",
        "        cursor.execute(\"\"\"\n",
        "        SELECT q.id, q.title, q.type\n",
        "        FROM questions q\n",
        "        JOIN posts p ON q.post_id = p.id\n",
        "        WHERE p.status = 'open' AND p.nr_forecasters > 10\n",
        "        ORDER BY p.nr_forecasters DESC\n",
        "        LIMIT ?\n",
        "        \"\"\", (sample_size,))\n",
        "\n",
        "        question_ids = [row[0] for row in cursor.fetchall()]\n",
        "\n",
        "    print(f\"üìä Fetching detailed data for {len(question_ids)} questions...\")\n",
        "\n",
        "    detailed_data = []\n",
        "    for idx, q_id in enumerate(question_ids, 1):\n",
        "        try:\n",
        "            url = f\"{api_url}/questions/{q_id}/\"\n",
        "            response = requests.get(url, headers=headers)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "\n",
        "                # Store aggregation data if available\n",
        "                if 'aggregations' in data:\n",
        "                    for agg_type, agg_data in data['aggregations'].items():\n",
        "                        if agg_data and 'latest' in agg_data and agg_data['latest']:\n",
        "                            latest = agg_data['latest']\n",
        "                            cursor.execute(\"\"\"\n",
        "                            INSERT INTO aggregations\n",
        "                            (question_id, aggregation_type, start_time, end_time,\n",
        "                             forecaster_count, centers, interval_lower_bounds,\n",
        "                             interval_upper_bounds, forecast_values)\n",
        "                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "                            \"\"\", (\n",
        "                                q_id,\n",
        "                                agg_type,\n",
        "                                latest.get('start_time'),\n",
        "                                latest.get('end_time'),\n",
        "                                latest.get('forecaster_count'),\n",
        "                                json.dumps(latest.get('centers')),\n",
        "                                json.dumps(latest.get('interval_lower_bounds')),\n",
        "                                json.dumps(latest.get('interval_upper_bounds')),\n",
        "                                json.dumps(latest.get('forecast_values'))\n",
        "                            ))\n",
        "\n",
        "                detailed_data.append(data)\n",
        "\n",
        "                if idx % 10 == 0:\n",
        "                    print(f\"  üìà Progress: {idx}/{len(question_ids)} questions processed\")\n",
        "\n",
        "            time.sleep(0.1)  # Rate limiting\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ö†Ô∏è Error fetching question {q_id}: {e}\")\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    print(f\"‚úÖ Fetched detailed data for {len(detailed_data)} questions\")\n",
        "    return detailed_data\n",
        "\n",
        "# Execute detailed fetching for top questions\n",
        "detailed_questions = fetch_question_details(sample_size=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYXvJRfe6kwD",
        "outputId": "ad621f3a-0d00-42d2-e3c3-418b36f00e26"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Fetching detailed data for 20 questions...\n",
            "‚úÖ Fetched detailed data for 0 questions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_comments_for_posts(post_ids=None, limit=10):\n",
        "    \"\"\"Fetch comments for specified posts\"\"\"\n",
        "\n",
        "    api_url = os.getenv(\"METACULUS_API_URL\", \"https://www.metaculus.com/api\")\n",
        "    api_token = os.getenv(\"METACULUS_API_TOKEN\")\n",
        "    db_path = os.getenv(\"DB_PATH\")\n",
        "\n",
        "    headers = {}\n",
        "    if api_token and api_token != \"YOUR_TOKEN_HERE\":\n",
        "        headers[\"Authorization\"] = f\"Token {api_token}\"\n",
        "\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # If no specific IDs provided, get posts with most comments\n",
        "    if post_ids is None:\n",
        "        cursor.execute(\"\"\"\n",
        "        SELECT id, title, comment_count\n",
        "        FROM posts\n",
        "        WHERE status = 'open' AND comment_count > 0\n",
        "        ORDER BY comment_count DESC\n",
        "        LIMIT ?\n",
        "        \"\"\", (limit,))\n",
        "\n",
        "        post_data = cursor.fetchall()\n",
        "        post_ids = [row[0] for row in post_data]\n",
        "\n",
        "    print(f\"üí¨ Fetching comments for {len(post_ids)} posts...\")\n",
        "\n",
        "    all_comments = []\n",
        "    for idx, post_id in enumerate(post_ids, 1):\n",
        "        try:\n",
        "            url = f\"{api_url}/comments/\"\n",
        "            params = {\n",
        "                \"post\": post_id,\n",
        "                \"limit\": 100\n",
        "            }\n",
        "\n",
        "            response = requests.get(url, headers=headers, params=params)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                comments = data.get('results', [])\n",
        "\n",
        "                for comment in comments:\n",
        "                    cursor.execute(\"\"\"\n",
        "                    INSERT OR REPLACE INTO comments\n",
        "                    (id, post_id, author_id, author_username, parent_id,\n",
        "                     root_id, text, vote_score, included_forecast, created_at)\n",
        "                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "                    \"\"\", (\n",
        "                        comment.get('id'),\n",
        "                        post_id,\n",
        "                        comment.get('author', {}).get('id'),\n",
        "                        comment.get('author', {}).get('username'),\n",
        "                        comment.get('parent_id'),\n",
        "                        comment.get('root_id'),\n",
        "                        comment.get('text'),\n",
        "                        comment.get('vote_score'),\n",
        "                        comment.get('included_forecast'),\n",
        "                        comment.get('created_at')\n",
        "                    ))\n",
        "\n",
        "                all_comments.extend(comments)\n",
        "\n",
        "                if idx % 5 == 0:\n",
        "                    print(f\"  üí≠ Progress: {idx}/{len(post_ids)} posts processed\")\n",
        "\n",
        "            time.sleep(0.1)  # Rate limiting\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ö†Ô∏è Error fetching comments for post {post_id}: {e}\")\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    print(f\"‚úÖ Fetched {len(all_comments)} comments\")\n",
        "    return all_comments\n",
        "\n",
        "# Execute comment fetching\n",
        "comments = fetch_comments_for_posts(limit=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3eb0cZc7Fgu",
        "outputId": "fb97185c-00c7-4715-9c59-4cc8caab4c30"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üí¨ Fetching comments for 10 posts...\n",
            "  ‚ö†Ô∏è Error fetching comments for post 349: Error binding parameter 9: type 'dict' is not supported\n",
            "  ‚ö†Ô∏è Error fetching comments for post 2534: Error binding parameter 9: type 'dict' is not supported\n",
            "  ‚ö†Ô∏è Error fetching comments for post 353: Error binding parameter 9: type 'dict' is not supported\n",
            "  üí≠ Progress: 5/10 posts processed\n",
            "  ‚ö†Ô∏è Error fetching comments for post 384: Error binding parameter 9: type 'dict' is not supported\n",
            "  ‚ö†Ô∏è Error fetching comments for post 18546: Error binding parameter 9: type 'dict' is not supported\n",
            "  üí≠ Progress: 10/10 posts processed\n",
            "‚úÖ Fetched 500 comments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyze Question Types and Statistics"
      ],
      "metadata": {
        "id": "BrdnUOFU7NST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_questions():\n",
        "    \"\"\"Generate analysis and statistics of fetched questions\"\"\"\n",
        "\n",
        "    db_path = os.getenv(\"DB_PATH\")\n",
        "    conn = sqlite3.connect(db_path)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìä METACULUS TRACKER - ANALYSIS REPORT\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Posts summary\n",
        "    posts_df = pd.read_sql_query(\"\"\"\n",
        "        SELECT\n",
        "            COUNT(*) as total_posts,\n",
        "            SUM(CASE WHEN status = 'open' THEN 1 ELSE 0 END) as open_posts,\n",
        "            SUM(CASE WHEN resolved = 1 THEN 1 ELSE 0 END) as resolved_posts,\n",
        "            AVG(nr_forecasters) as avg_forecasters,\n",
        "            SUM(forecasts_count) as total_forecasts\n",
        "        FROM posts\n",
        "    \"\"\", conn)\n",
        "\n",
        "    print(\"\\nüìà POSTS OVERVIEW:\")\n",
        "    print(f\"   Total Posts: {posts_df['total_posts'].iloc[0]:,}\")\n",
        "    print(f\"   Open Posts: {posts_df['open_posts'].iloc[0]:,}\")\n",
        "    print(f\"   Resolved Posts: {posts_df['resolved_posts'].iloc[0]:,}\")\n",
        "    print(f\"   Avg Forecasters per Post: {posts_df['avg_forecasters'].iloc[0]:.1f}\")\n",
        "    print(f\"   Total Forecasts: {posts_df['total_forecasts'].iloc[0]:,}\")\n",
        "\n",
        "    # Question types breakdown\n",
        "    questions_df = pd.read_sql_query(\"\"\"\n",
        "        SELECT\n",
        "            type,\n",
        "            COUNT(*) as count,\n",
        "            AVG(CASE WHEN status = 'open' THEN 1 ELSE 0 END) as pct_open\n",
        "        FROM questions\n",
        "        GROUP BY type\n",
        "        ORDER BY count DESC\n",
        "    \"\"\", conn)\n",
        "\n",
        "    print(\"\\nüéØ QUESTION TYPES:\")\n",
        "    for idx, row in questions_df.iterrows():\n",
        "        if row['type']:\n",
        "            print(f\"   {row['type'].capitalize()}: {row['count']:,} questions ({row['pct_open']*100:.1f}% open)\")\n",
        "\n",
        "    # Top posts by forecasters\n",
        "    print(\"\\nüîù TOP 5 POSTS BY FORECASTERS:\")\n",
        "    top_posts = pd.read_sql_query(\"\"\"\n",
        "        SELECT title, nr_forecasters, forecasts_count, status\n",
        "        FROM posts\n",
        "        ORDER BY nr_forecasters DESC\n",
        "        LIMIT 5\n",
        "    \"\"\", conn)\n",
        "\n",
        "    for idx, row in top_posts.iterrows():\n",
        "        title = row['title'][:60] + \"...\" if len(row['title']) > 60 else row['title']\n",
        "        print(f\"   {idx+1}. {title}\")\n",
        "        print(f\"      Forecasters: {row['nr_forecasters']:,} | Forecasts: {row['forecasts_count']:,} | Status: {row['status']}\")\n",
        "\n",
        "    # Recent activity\n",
        "    recent_df = pd.read_sql_query(\"\"\"\n",
        "        SELECT\n",
        "            DATE(published_at) as date,\n",
        "            COUNT(*) as posts_published\n",
        "        FROM posts\n",
        "        WHERE published_at IS NOT NULL\n",
        "        GROUP BY DATE(published_at)\n",
        "        ORDER BY date DESC\n",
        "        LIMIT 7\n",
        "    \"\"\", conn)\n",
        "\n",
        "    if len(recent_df) > 0:\n",
        "        print(\"\\nüìÖ RECENT PUBLISHING ACTIVITY (Last 7 days with posts):\")\n",
        "        for idx, row in recent_df.iterrows():\n",
        "            print(f\"   {row['date']}: {row['posts_published']} posts\")\n",
        "\n",
        "    # Aggregation statistics\n",
        "    agg_stats = pd.read_sql_query(\"\"\"\n",
        "        SELECT\n",
        "            COUNT(DISTINCT question_id) as questions_with_aggregations,\n",
        "            COUNT(*) as total_aggregations,\n",
        "            AVG(forecaster_count) as avg_forecasters_in_agg\n",
        "        FROM aggregations\n",
        "    \"\"\", conn)\n",
        "\n",
        "    if agg_stats['total_aggregations'].iloc[0] > 0:\n",
        "        print(\"\\nüìä AGGREGATION DATA:\")\n",
        "        print(f\"   Questions with Aggregations: {agg_stats['questions_with_aggregations'].iloc[0]:,}\")\n",
        "        print(f\"   Total Aggregation Records: {agg_stats['total_aggregations'].iloc[0]:,}\")\n",
        "        print(f\"   Avg Forecasters in Aggregations: {agg_stats['avg_forecasters_in_agg'].iloc[0]:.1f}\")\n",
        "\n",
        "    # Comments statistics\n",
        "    comment_stats = pd.read_sql_query(\"\"\"\n",
        "        SELECT\n",
        "            COUNT(*) as total_comments,\n",
        "            COUNT(DISTINCT post_id) as posts_with_comments,\n",
        "            COUNT(DISTINCT author_id) as unique_commenters,\n",
        "            AVG(vote_score) as avg_vote_score\n",
        "        FROM comments\n",
        "    \"\"\", conn)\n",
        "\n",
        "    if comment_stats['total_comments'].iloc[0] > 0:\n",
        "        print(\"\\nüí¨ COMMENT STATISTICS:\")\n",
        "        print(f\"   Total Comments: {comment_stats['total_comments'].iloc[0]:,}\")\n",
        "        print(f\"   Posts with Comments: {comment_stats['posts_with_comments'].iloc[0]:,}\")\n",
        "        print(f\"   Unique Commenters: {comment_stats['unique_commenters'].iloc[0]:,}\")\n",
        "        print(f\"   Avg Vote Score: {comment_stats['avg_vote_score'].iloc[0]:.2f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"‚úÖ Analysis complete!\")\n",
        "    print(f\"üìÅ Database location: {db_path}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "# Execute analysis\n",
        "analyze_questions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ5KGzOH7FjF",
        "outputId": "19c411ec-0a7c-46b9-db6f-1cdef20b5ab2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üìä METACULUS TRACKER - ANALYSIS REPORT\n",
            "============================================================\n",
            "\n",
            "üìà POSTS OVERVIEW:\n",
            "   Total Posts: 11,006\n",
            "   Open Posts: 2,882\n",
            "   Resolved Posts: 6,999\n",
            "   Avg Forecasters per Post: 70.9\n",
            "   Total Forecasts: 2,620,355\n",
            "\n",
            "üéØ QUESTION TYPES:\n",
            "   Binary: 8,675 questions (25.8% open)\n",
            "   Numeric: 4,689 questions (27.0% open)\n",
            "   Date: 1,170 questions (58.9% open)\n",
            "   Multiple_choice: 671 questions (12.8% open)\n",
            "   Discrete: 43 questions (62.8% open)\n",
            "\n",
            "üîù TOP 5 POSTS BY FORECASTERS:\n",
            "   1. Will SpaceX land people on Mars before 2030?\n",
            "      Forecasters: 4,382 | Forecasts: 7,975 | Status: open\n",
            "   2. Who will be elected US President in 2024?\n",
            "      Forecasters: 3,639 | Forecasts: 75,721 | Status: resolved\n",
            "   3. Will there be a \"World War Three\" before 2050?\n",
            "      Forecasters: 2,888 | Forecasts: 4,503 | Status: open\n",
            "   4. Will there be Human-machine intelligence parity before 2040?\n",
            "      Forecasters: 2,730 | Forecasts: 4,973 | Status: open\n",
            "   5. Will the following Trump Cabinet nominees withdraw or be vot...\n",
            "      Forecasters: 2,226 | Forecasts: 18,845 | Status: resolved\n",
            "\n",
            "üìÖ RECENT PUBLISHING ACTIVITY (Last 7 days with posts):\n",
            "   2025-11-04: 4 posts\n",
            "   2025-11-03: 6 posts\n",
            "   2025-11-02: 3 posts\n",
            "   2025-11-01: 2 posts\n",
            "   2025-10-31: 10 posts\n",
            "   2025-10-30: 5 posts\n",
            "   2025-10-29: 8 posts\n",
            "\n",
            "üí¨ COMMENT STATISTICS:\n",
            "   Total Comments: 532\n",
            "   Posts with Comments: 10\n",
            "   Unique Commenters: 100\n",
            "   Avg Vote Score: 1.83\n",
            "\n",
            "============================================================\n",
            "‚úÖ Analysis complete!\n",
            "üìÅ Database location: /content/metaculus_tracker.db\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def monitor_high_activity_questions(threshold_forecasters=100, check_interval_seconds=60, duration_minutes=3):\n",
        "    \"\"\"Monitor questions with high forecasting activity\"\"\"\n",
        "\n",
        "    db_path = os.getenv(\"DB_PATH\")\n",
        "    api_url = os.getenv(\"METACULUS_API_URL\", \"https://www.metaculus.com/api\")\n",
        "    api_token = os.getenv(\"METACULUS_API_TOKEN\")\n",
        "\n",
        "    headers = {}\n",
        "    if api_token and api_token != \"YOUR_TOKEN_HERE\":\n",
        "        headers[\"Authorization\"] = f\"Token {api_token}\"\n",
        "\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Get high-activity questions\n",
        "    cursor.execute(\"\"\"\n",
        "        SELECT p.id, p.title, p.nr_forecasters, p.forecasts_count\n",
        "        FROM posts p\n",
        "        WHERE p.status = 'open' AND p.nr_forecasters >= ?\n",
        "        ORDER BY p.nr_forecasters DESC\n",
        "        LIMIT 5\n",
        "    \"\"\", (threshold_forecasters,))\n",
        "\n",
        "    high_activity_posts = cursor.fetchall()\n",
        "\n",
        "    if not high_activity_posts:\n",
        "        print(f\"‚ùå No questions found with {threshold_forecasters}+ forecasters\")\n",
        "        return\n",
        "\n",
        "    print(f\"üì° Monitoring {len(high_activity_posts)} high-activity questions\")\n",
        "    print(f\"   Threshold: {threshold_forecasters}+ forecasters\")\n",
        "    print(f\"   Duration: {duration_minutes} minutes\")\n",
        "    print(f\"   Check interval: {check_interval_seconds} seconds\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for post in high_activity_posts:\n",
        "        title = post[1][:50] + \"...\" if len(post[1]) > 50 else post[1]\n",
        "        print(f\"   ‚Ä¢ {title}\")\n",
        "        print(f\"     Forecasters: {post[2]:,} | Forecasts: {post[3]:,}\")\n",
        "    print(\"-\"*60)\n",
        "\n",
        "    start_time = datetime.now()\n",
        "    end_time = start_time + pd.Timedelta(minutes=duration_minutes)\n",
        "    check_count = 0\n",
        "\n",
        "    print(\"üîÑ Starting monitoring...\")\n",
        "\n",
        "    while datetime.now() < end_time:\n",
        "        check_count += 1\n",
        "        current_time = datetime.now()\n",
        "        elapsed = (current_time - start_time).total_seconds()\n",
        "        remaining = (end_time - current_time).total_seconds()\n",
        "\n",
        "        print(f\"\\n‚è±Ô∏è Check #{check_count} | Elapsed: {elapsed:.0f}s | Remaining: {remaining:.0f}s\")\n",
        "\n",
        "        for post_id, title, _, _ in high_activity_posts:\n",
        "            try:\n",
        "                # Fetch current data\n",
        "                url = f\"{api_url}/posts/{post_id}/\"\n",
        "                response = requests.get(url, headers=headers)\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    data = response.json()\n",
        "                    new_forecasters = data.get('nr_forecasters', 0)\n",
        "                    new_forecasts = data.get('forecasts_count', 0)\n",
        "\n",
        "                    # Check for changes\n",
        "                    cursor.execute(\"\"\"\n",
        "                        SELECT nr_forecasters, forecasts_count\n",
        "                        FROM posts\n",
        "                        WHERE id = ?\n",
        "                    \"\"\", (post_id,))\n",
        "\n",
        "                    old_data = cursor.fetchone()\n",
        "                    if old_data:\n",
        "                        old_forecasters, old_forecasts = old_data\n",
        "\n",
        "                        if new_forecasters != old_forecasters or new_forecasts != old_forecasts:\n",
        "                            print(f\"   üìà UPDATE: {title[:40]}...\")\n",
        "                            print(f\"      Forecasters: {old_forecasters} ‚Üí {new_forecasters} ({new_forecasters - old_forecasters:+d})\")\n",
        "                            print(f\"      Forecasts: {old_forecasts} ‚Üí {new_forecasts} ({new_forecasts - old_forecasts:+d})\")\n",
        "\n",
        "                            # Update database\n",
        "                            cursor.execute(\"\"\"\n",
        "                                UPDATE posts\n",
        "                                SET nr_forecasters = ?, forecasts_count = ?\n",
        "                                WHERE id = ?\n",
        "                            \"\"\", (new_forecasters, new_forecasts, post_id))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ö†Ô∏è Error checking post {post_id}: {e}\")\n",
        "\n",
        "        conn.commit()\n",
        "\n",
        "        # Wait for next check\n",
        "        if datetime.now() < end_time:\n",
        "            time.sleep(min(check_interval_seconds, (end_time - datetime.now()).total_seconds()))\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚úÖ Monitoring complete!\")\n",
        "    print(f\"   Total checks: {check_count}\")\n",
        "    print(f\"   Duration: {(datetime.now() - start_time).total_seconds():.1f} seconds\")\n",
        "\n",
        "# Execute monitoring (will run for 3 minutes)\n",
        "monitor_high_activity_questions(threshold_forecasters=50, check_interval_seconds=30, duration_minutes=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS7uw7C47Fla",
        "outputId": "559bbb18-cede-4e7f-93bf-3fadf03ef1b4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì° Monitoring 5 high-activity questions\n",
            "   Threshold: 50+ forecasters\n",
            "   Duration: 3 minutes\n",
            "   Check interval: 30 seconds\n",
            "============================================================\n",
            "   ‚Ä¢ Will SpaceX land people on Mars before 2030?\n",
            "     Forecasters: 4,382 | Forecasts: 7,975\n",
            "   ‚Ä¢ Will there be a \"World War Three\" before 2050?\n",
            "     Forecasters: 2,888 | Forecasts: 4,503\n",
            "   ‚Ä¢ Will there be Human-machine intelligence parity be...\n",
            "     Forecasters: 2,730 | Forecasts: 4,973\n",
            "   ‚Ä¢ Will any conclusive evidence for extraterrestrial ...\n",
            "     Forecasters: 1,660 | Forecasts: 2,376\n",
            "   ‚Ä¢ Will someone born before 2001 live to be 150?\n",
            "     Forecasters: 1,572 | Forecasts: 3,026\n",
            "------------------------------------------------------------\n",
            "üîÑ Starting monitoring...\n",
            "\n",
            "‚è±Ô∏è Check #1 | Elapsed: 0s | Remaining: 180s\n",
            "\n",
            "‚è±Ô∏è Check #2 | Elapsed: 31s | Remaining: 149s\n",
            "\n",
            "‚è±Ô∏è Check #3 | Elapsed: 63s | Remaining: 117s\n",
            "\n",
            "‚è±Ô∏è Check #4 | Elapsed: 94s | Remaining: 86s\n",
            "\n",
            "‚è±Ô∏è Check #5 | Elapsed: 125s | Remaining: 55s\n",
            "\n",
            "‚è±Ô∏è Check #6 | Elapsed: 157s | Remaining: 23s\n",
            "\n",
            "============================================================\n",
            "‚úÖ Monitoring complete!\n",
            "   Total checks: 6\n",
            "   Duration: 180.0 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MMMBk0AA7Fn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "44Fb58gt7Fqm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}